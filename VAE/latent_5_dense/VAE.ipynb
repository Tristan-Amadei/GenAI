{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ultimate-garlic",
   "metadata": {
    "id": "56089271-a900-488d-bae7-96209e418f83",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "permanent-aquarium",
   "metadata": {
    "id": "14c1e07c-4ef7-40c2-93dc-0d0d07499a59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from metrics import anderson_darling, kendall_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-decrease",
   "metadata": {
    "id": "dd62f6aa-4b39-4482-b8da-d5451799cbb4"
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "olive-puppy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "c7caf1aa-3091-4c0f-b8ab-655ff1fe20ca",
    "outputId": "c8af63a0-8d35-4873-922b-263df98d0c9e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index1</th>\n",
       "      <th>index2</th>\n",
       "      <th>index3</th>\n",
       "      <th>index4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.006947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017828</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.007382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021115</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.011499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.005106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.005003</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.006467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index1    index2    index3    index4\n",
       "0    0.012495  0.011126  0.003252  0.006625\n",
       "1    0.011439  0.002691  0.001206  0.006947\n",
       "2    0.000632  0.007277  0.004049  0.000074\n",
       "3    0.017828  0.028210  0.007758  0.007382\n",
       "4    0.021115  0.019642  0.009238  0.011499\n",
       "..        ...       ...       ...       ...\n",
       "741  0.001938  0.008833  0.003927  0.005106\n",
       "742  0.005003  0.018943  0.003057  0.001988\n",
       "743  0.007683  0.001958  0.007002  0.006467\n",
       "744  0.003396  0.001280  0.007621  0.001680\n",
       "745  0.004591  0.006675  0.007600  0.009560\n",
       "\n",
       "[746 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data_train_log_return.csv\", header=None).drop(columns=[0])\n",
    "data.columns = [f'index{i}' for i in range(1, 5)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "square-joshua",
   "metadata": {
    "id": "47f89d18-b551-43ae-8ed0-be83f5964f7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdf9cd4-5609-4f1b-ae52-d874a0548149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FILE = 'results.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-stand",
   "metadata": {
    "id": "7bd52814-7af7-4bb9-85f0-ec04fbe384d1"
   },
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-image",
   "metadata": {
    "id": "aaef4a14-f342-4e4d-be2e-c8cdfb7788fc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trist\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "funny-shooting",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGIuYUELUWcH",
    "outputId": "3ebd1d75-30b4-4b04-9ec8-33941bb4cc0b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.15.0\n",
      "Eager mode:  True\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-kitty",
   "metadata": {
    "id": "bba37a9f-c900-467b-a60e-1cfd9c70d857"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "anticipated-telephone",
   "metadata": {
    "id": "6bc13fe3-6be5-40e0-b0ca-fcef77b20098",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, input_dim=data.shape[1]):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                # No activation\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                # No activation\n",
    "                tf.keras.layers.Dense(input_dim)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(data.shape[0], self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "split-dynamics",
   "metadata": {
    "id": "943c268f-83f8-48b7-926f-49843a32f88d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent)\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "generic-philip",
   "metadata": {
    "id": "5d665dbc-5610-4ca8-aa22-4dcfe681bfb8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_samples(model, test_sample):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    return predictions, mean, logvar, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-blackberry",
   "metadata": {
    "id": "9b4dadbf-0ba4-4ab7-b9a1-5c26e0322309"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simple-optimization",
   "metadata": {
    "id": "63b45b47-7a13-422e-8c73-885d22639587",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = tf.cast(data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dental-nicaragua",
   "metadata": {
    "id": "TbwYdN45iYaB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def histogram(ax, data, label=\"\"):\n",
    "    sns.histplot(data, kde=True, ax=ax, stat='density', label=label)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "def plot_distribution(model, generated_sample, title='', save=None):\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(11, 8))\n",
    "    for i in range(4):\n",
    "        histogram(axs[i][0], data[:, i], label=f'True index{i+1}')\n",
    "        histogram(axs[i][1], generated_sample[:, i], label=f'Generated index{i+1}')\n",
    "    for ax in axs:\n",
    "        for ax_i in ax:\n",
    "            ax_i.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.suptitle(title)\n",
    "    if save is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save)\n",
    "        plt.close()\n",
    "\n",
    "def plot_distribution_errors(model, generated_sample, errors):\n",
    "    fig, axs = plt.subplots(4, 3, figsize=(14, 8))\n",
    "    for i in range(4):\n",
    "        histogram(axs[i][0], data[:, i], label=f'True index{i+1}')\n",
    "        histogram(axs[i][1], generated_sample[:, i], label=f'Gen index{i+1}')\n",
    "\n",
    "    axs[0][2].plot(errors['elbo'], label='ELBO')\n",
    "    axs[0][2].grid('on')\n",
    "    \n",
    "    axs[1][2].plot(errors['anderson'], label='Anderson')\n",
    "    axs[1][2].grid('on')\n",
    "\n",
    "    axs[2][2].plot(errors['anderson'][-10:], label='Anderson - last 10')\n",
    "    axs[2][2].grid('on')\n",
    "\n",
    "    axs[3][2].plot(errors['kendall'], label='Kendall')\n",
    "    axs[3][2].grid('on')\n",
    "\n",
    "    for i, ax in enumerate(axs):\n",
    "        for j, ax_j in enumerate(ax):\n",
    "            ax_j.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compliant-scheme",
   "metadata": {
    "id": "d6287d04-75d8-418a-adfe-4461c9415048",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trist\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 5\n",
    "model = VAE(latent_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-2)\n",
    "loss = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "emotional-aside",
   "metadata": {
    "id": "YGXAnR3cLaGz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(model, generated_sample, errors):\n",
    "    random_anderson = anderson_darling(data, generated_sample.numpy())\n",
    "    random_kendall = kendall_error(data, generated_sample.numpy())\n",
    "\n",
    "    errors['anderson'].append(random_anderson)\n",
    "    errors['kendall'].append(random_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smaller-deviation",
   "metadata": {
    "id": "kw6laJ4EO50c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = {}\n",
    "errors['elbo'] = []\n",
    "errors['anderson'] = []\n",
    "errors['kendall'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-german",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823
    },
    "id": "49232745-9e47-4c57-b0bb-c1931b855031",
    "outputId": "d06de5d4-2457-492e-d86b-edd0306fc1c3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8000, ELBO: -181.70420837402344, time: 64.5332s for 1000 epochs\n"
     ]
    }
   ],
   "source": [
    "epochs = 100_000\n",
    "display_every = 1000\n",
    "patience = 1000\n",
    "best_elbo = float('-inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_step(model, X, optimizer)\n",
    "\n",
    "    loss(compute_loss(model, X))\n",
    "    elbo = -loss.result()\n",
    "    errors['elbo'].append(elbo)\n",
    "\n",
    "    # check for patience\n",
    "    if elbo > best_elbo:\n",
    "        best_elbo = elbo\n",
    "        no_improvement_count = 0  # reset the counter\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    if no_improvement_count >= patience:\n",
    "        display.clear_output(wait=False)\n",
    "        print(f'Patience! Epoch: {epoch}, ELBO: {elbo}')\n",
    "        random_noise = np.random.exponential(2e-2, size=(data.shape))\n",
    "        generated_sample, *_ = generate_samples(model, random_noise)\n",
    "        plot_distribution_errors(model, generated_sample, errors)\n",
    "        break\n",
    "\n",
    "    if epoch % display_every == 0 or epoch == 1:\n",
    "        display.clear_output(wait=False)\n",
    "        random_noise = np.random.exponential(2e-2, size=(data.shape))\n",
    "        generated_sample, *_ = generate_samples(model, random_noise)\n",
    "        compute_metrics(model, generated_sample, errors)\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch: {epoch}, ELBO: {elbo}, time: {round(end_time-start_time, 4)}s for {display_every} epochs\")\n",
    "        start_time = time.time()\n",
    "        plot_distribution_errors(model, generated_sample, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a400c-45fe-423c-8a4d-20b871edc0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def redirect_to_file(model, f):\n",
    "    sys.stdout = f\n",
    "    model.summary()\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "def write_architecture(model, file_=FILE):\n",
    "    with open(file_, \"a\") as f:\n",
    "        f.write(f\"Latent dimension = {latent_dim}, dense: {len(model.encoder.layers) > 2}\")\n",
    "        redirect_to_file(model.encoder, f)\n",
    "        f.write('\\n')\n",
    "        redirect_to_file(model.decoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-rouge",
   "metadata": {
    "id": "45875c9b-a0d8-4e7b-9566-22739852f0bd"
   },
   "source": [
    "## Generate new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-exercise",
   "metadata": {},
   "source": [
    "### Exponential noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-trinity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "207fb40f-897e-4786-a13a-b5c420a8b3b5",
    "outputId": "ce8fa073-2616-4aa1-bebf-4620cfa49f87",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_noise = np.random.exponential(2e-2, size=(data.shape))\n",
    "generated_sample, *_ = generate_samples(model, random_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-bunch",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_distribution(model, generated_sample, title='Exponential noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-inquiry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8fd3693-ad61-4301-93aa-1bc42a658f09",
    "outputId": "6d74e410-b9c5-476c-f483-cf06199653dd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "anderson_darling(data, generated_sample.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-lightweight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fcab680-ac68-44f2-84a3-2b453d78a49d",
    "outputId": "8a5882ef-3bd4-4463-8e8d-00b7a5e82d6e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "kendall_error(data, generated_sample.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-horror",
   "metadata": {},
   "source": [
    "### Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-houston",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_noise = np.random.normal(0, 2e-2, size=(data.shape))\n",
    "generated_sample, *_ = generate_samples(model, random_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-humanity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_distribution(model, generated_sample, title='Gaussian noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-vertex",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anderson_darling(data, generated_sample.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-accuracy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kendall_error(data, generated_sample.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-america",
   "metadata": {},
   "source": [
    "### Absolute Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-kenya",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_noise = abs(np.random.normal(0, 2e-2, size=(data.shape)))\n",
    "generated_sample, *_ = generate_samples(model, random_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-swaziland",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_distribution(model, generated_sample, title='Gaussian noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-excess",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anderson_darling(data, generated_sample.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-concentrate",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kendall_error(data, generated_sample.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec963e-42bb-4421-8775-c1a01f5cc4b4",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e647e-77d6-435f-b37f-f31f99ab0e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_latent_var(mean, logvar, z, file_):\n",
    "    mean_df = pd.DataFrame(mean.numpy(), columns=[f'latent_mean_{i}' for i in range(mean.shape[1])])\n",
    "    logvar_df = pd.DataFrame(logvar.numpy(), columns=[f'latent_logvar_{i}' for i in range(logvar.shape[1])])\n",
    "    z_df = pd.DataFrame(z.numpy(), columns=['Gaussian_latent_var_feature_{i}' for i in range(z.shape[1])])\n",
    "    all_df = pd.concat([mean_df, logvar_df, z_df], axis=1)\n",
    "    all_df.to_csv(file_)\n",
    "\n",
    "def write_noise(model, csv, images, file_=FILE, cv=50):\n",
    "    noises = [np.random.exponential(1e-2, size=(data.shape)), np.random.normal(0, 1e-2, size=(data.shape)), abs(np.random.normal(0, 1e-2, size=(data.shape)))]\n",
    "    names = ['Exponential noise: 1e-2', 'Gaussian noise: 0, 1e-2', 'Absolute value Gaussian noise: 0, 1e-2']\n",
    "    filenames = ['exp', 'norm', 'abs_norm']\n",
    "    \n",
    "    def create_dir_if_not(dir_):\n",
    "        if not os.path.isdir(dir_):\n",
    "            os.mkdir(dir_)\n",
    "    \n",
    "    def compute_metrics_noise(noise, i):\n",
    "        anderson = 0\n",
    "        kendall = 0\n",
    "        for _ in range(cv):\n",
    "            generated_sample, mean, logvar, z = generate_samples(model, noise)\n",
    "            anderson += anderson_darling(data, generated_sample.numpy())\n",
    "            kendall += kendall_error(data, generated_sample.numpy())\n",
    "        anderson /= cv\n",
    "        kendall /= cv\n",
    "        with open(file_, 'a') as f:\n",
    "            f.write(f'Anderson: {anderson}, Kendall: {kendall}')\n",
    "            \n",
    "        create_dir_if_not(csv)\n",
    "        csv_file = csv if csv.endswith('/') else csv + '/'\n",
    "        csv_file += filenames[i] + '.csv'\n",
    "        pd.DataFrame(generated_sample.numpy()).to_csv(csv_file, index=False)\n",
    "        latent_file = csv if csv.endswith('/') else csv + '/'\n",
    "        latent_file += filenames[i] + '_latent.csv'\n",
    "        save_latent_var(mean, logvar, z, latent_file)\n",
    "        \n",
    "        create_dir_if_not(images)\n",
    "        images_file = images if images.endswith('/') else images + '/'\n",
    "        images_file += filenames[i] + '.png'\n",
    "        plot_distribution(model, generated_sample, title=names[i], save=images_file)\n",
    "    \n",
    "    for i in range(len(noises)):\n",
    "        with open(file_, 'a') as f:\n",
    "            f.write('\\n\\n' + names[i] + '\\n')\n",
    "        compute_metrics_noise(noises[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1f038-e034-4d47-869c-7d28d43450ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_architecture(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-annual",
   "metadata": {
    "id": "tCM8lxMR6Jnf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c631c-c4bc-485b-b82c-fe76e694a161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_noise(model, './gen_samples', './gen_images', file_=FILE, cv=20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
